{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5cc957-9f64-47a7-b07f-2fd83656716f",
   "metadata": {},
   "source": [
    "# Lecture 7b Measures of Distance\n",
    "__Math 3280: Data Mining__\n",
    "\n",
    "__Outline__\n",
    "1. Jaccard Similarity\n",
    "2. Euclidean Distance\n",
    "3. Cosine Distance\n",
    "\n",
    "__Reading__ \n",
    "* Leskovec, Sections 3.1, 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a7ccde",
   "metadata": {},
   "source": [
    "A common problem in data science is to compare one dataset to another. This helps in machine learning problems, as well as helps to find similar items to identify patterns.\n",
    "\n",
    "The easiest method is to go through item by item and compare it with all other items. However, if there are 1 million items, then that is 1 trillion potential pairs to look through.\n",
    "\n",
    "In this chapter, we'll look at a technique, Locality-Sensitive Hashing, which focuses only on pairs likely to be similar (candidate pairs), while ignoring other pairs.\n",
    "\n",
    "* Jaccard Similarity\n",
    "* Shingling\n",
    "* Minhashing\n",
    "* Locality-Sensitive Hashing (LSH)\n",
    "  * LSH for documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560d099",
   "metadata": {},
   "source": [
    "## Jaccard Similarity\n",
    "The Jaccard Similarity compares two pieces of information to see how similar they are. Each row is a set\n",
    "The calculation is,\n",
    "$$J(S,T) = \\frac{|S\\cap T|}{|S\\cup T|}$$\n",
    "\n",
    "A simple example:\n",
    "$$A = \\{1, 3, 5\\} \\qquad B = \\{3, 4, 5, 6\\}$$\n",
    "Venn diagram (Square brackets encompass elements of A, round brackets encompass elements of B):\n",
    "$$\\Big[1 \\Big( 3, 5 \\Big] 4, 6\\Big)$$\n",
    "\n",
    "There are 5 elements total, so $|A\\cup B| = 5$. Only 2 elements are in both, so $|A\\cup B| = 2$.\n",
    "$$J(A,B) = \\frac{|A\\cap B|}{|A\\cup B|} = \\frac{2}{5}$$\n",
    "\n",
    "There are two similarity calculations:\n",
    "* Jaccard Similarity\n",
    "  * Union is all elements, not repeated - just looking at possible values\n",
    "$$|A\\cup B| = \\big|\\{1, 3, 4, 5, 6\\}\\big| = 5 \\qquad J(A,B) = \\frac{2}{5}$$\n",
    "* Jaccard Bag Similarity\n",
    "  * Union is all elements in both sets combined, as if they were two bags mixed together\n",
    "$$|A\\cup B| = \\big|\\{1, 3, 5, 3, 4, 5, 6\\}\\big| = 7 \\qquad J_B(A,B) = \\frac{2}{7}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1c0f0",
   "metadata": {},
   "source": [
    "Example #2: You create a shopping list including,\n",
    "* Milk (2), eggs, bread, chips (3), salsa\n",
    "\n",
    "But you forget the shopping list. So, you get what you can remember, plus some additional things:\n",
    "* Milk (3), eggs, chips (1), salsa, yogurt, cheese, ice cream\n",
    "\n",
    "What is the Jaccard similarity?\n",
    "$$|list \\cap purchased| = |\\{\\text{milk, eggs, chips, salsa}\\}|=4$$\n",
    "$$|list \\cup purchased| = |\\{\\text{milk, eggs, bread, chips, salsa, yogurt, cheese, ice cream}\\}|=8$$\n",
    "$$J(list, purchased) = \\frac{|list \\cap purchased|}{|list \\cup purchased|} = \\frac{4}{8}=0.5$$\n",
    "\n",
    "Notice that we did not repeat milk or chips. For the Jaccard Similarity, we only consider similar items, not repeats. For the Jaccard Bag Similarity, we do consider repeats.\n",
    "* For chips, it was on the list 3 times, but we only bought 1, so it is only counted once (1)\n",
    "* For milk, it was bought 3 times, but only on the list 2 times, so there are only two (2) matched pairs\n",
    "  * $|list \\cap purchased|$ = |milk, milk, eggs, chips, salsa| = 5\n",
    "* The union is all items, even if repeated\n",
    "  * $|list \\cup purchased|$ = |milk, milk, eggs, bread, chips, chips, chips, salsa, milk, milk, milk, eggs, chips, salsa, yogurt, cheese, ice cream| = 17\n",
    "\n",
    "$$J_B(list, purchased) = \\frac{|list \\cap purchased|}{|list \\cup purchased|} = \\frac{5}{17}=0.294$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af20ee3-3e1e-464a-b806-0fc28559e238",
   "metadata": {},
   "source": [
    "Another example:\n",
    "\n",
    "|     |  S  |  T  |\n",
    "| --- | --- | --- |\n",
    "| x_0 |  1  |  0  |\n",
    "| x_1 |  0  |  1  |\n",
    "| x_2 |  0  |  0  |\n",
    "| x_3 |  1  |  1  |\n",
    "| x_4 |  0  |  1  |\n",
    "| x_5 |  1  |  0  |\n",
    "| x_6 |  1  |  1  | \n",
    "| x_7 |  0  |  0  |\n",
    "| x_8 |  1  |  1  |  \n",
    "| x_9 |  0  |  1  |\n",
    "\n",
    "To do this, we look at only positive results (entries with a \"1\"). The intersection would be where both $S$ and $T$ are 1:\n",
    "$$|S\\cap T| = 3$$\n",
    "\n",
    "The union would be all entries where either $S$ or $T$ have a 1:\n",
    "$$|S\\cup T| = 8$$\n",
    "\n",
    "We can consider, instead of a list of all datapoints, just count the number of all possibilities.\n",
    "\n",
    "|  S  |  T  |  #  |\n",
    "| --- | --- | --- |\n",
    "|  0  |  0  |  2  |\n",
    "|  0  |  1  |  3  |\n",
    "|  1  |  0  |  2  |\n",
    "|  1  |  1  |  3  |\n",
    "\n",
    "or, looking at it with a confusion matrix,\n",
    "\n",
    "|      |  S=1  |  S=0  |\n",
    "| ---: | :---: | :---: |\n",
    "|  T=1 |   3   |   3   |\n",
    "|  T=0 |   2   |   2   |\n",
    "\n",
    "$$|S\\cap T| = 3 \\qquad |S \\cup T| = 3+3+2 = 8$$\n",
    "\n",
    "Either way, the Jaccard Similarity is,\n",
    "$$|S\\cap T| = 3 \\qquad |S\\cup T| = 8 \\qquad J(S,T) = \\frac{|S\\cap T|}{|S\\cup T|} = \\frac{3}{8}$$\n",
    "\n",
    "The Jaccard Bag Similarity,\n",
    "$$J_B(S,T) = \\frac{3}{11}$$\n",
    "\n",
    "The Jaccard Similarity can be used in a variety of ways:\n",
    "* Similarity of Documents\n",
    "* Plagiarism\n",
    "* Mirror Pages\n",
    "* Articles from the Same Source\n",
    "* __Collaborative Filtering__\n",
    "  * On-line Purchases\n",
    "  * Movie Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfbea42",
   "metadata": {},
   "source": [
    "## Euclidean Distance\n",
    "We saw the Euclidean Distance at the beginning of the semester. The Euclidean Distance is just the physical straight-line distance between two points, also known as the Pythagorean Theorem and as the 2-norm.\n",
    "$$d = \\lVert x \\rVert_2 = \\sqrt{\\sum_i x_i^2}$$\n",
    "\n",
    "Because the 2-norm is the most common norm, we usually drop the subscript.\n",
    "$$\\lVert x \\rVert_2 = \\lVert x \\rVert$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def norm(x,n):\n",
    "  return sum(x**n)**(1/n)\n",
    "\n",
    "a = np.array([1,3])\n",
    "\n",
    "print(\"2-norm = \", norm(a,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5dac2",
   "metadata": {},
   "source": [
    "## Cosine Distance\n",
    "A low physical distance implies that two points are almost identical. However, is there a way to measure that two points have similar attributes despite being very different? \n",
    "\n",
    "Instead of looking at the physical distance between two points, we look at whether two points are pointing in similar, opposite, or perpendicular directions. We do this using the cosine-definition of the dot product.\n",
    "$$\\vec{x}\\cdot\\vec{y} = \\lVert x \\rVert\\lVert y \\rVert \\cos\\theta \\qquad\\qquad \\cos\\theta = \\frac{\\vec{x}\\cdot\\vec{y}}{\\lVert x \\rVert\\lVert y \\rVert} \\qquad\\qquad \\theta = \\arccos\\left(\\frac{\\vec{x}\\cdot\\vec{y}}{\\lVert x \\rVert\\lVert y \\rVert}\\right)$$\n",
    "\n",
    "__The angle $\\theta$ is the cosine distance.__ However, we often look at $\\cos\\theta$ instead as it becomes more intuitive.\n",
    "\n",
    "| The two points are             | $\\theta$                     | $\\cos\\theta$              |\n",
    "| -----------------------------: | :--------------------------: | :-----------------------: |\n",
    "|                                | $0 \\le \\theta \\le 2\\pi$      | $-1 \\le \\cos\\theta \\le 1$ |\n",
    "|       in similar directions if | $\\theta\\approx 0$ or $2\\pi$  | $\\cos\\theta \\approx 1$    |\n",
    "| in perpendicular directions if | $\\theta\\approx\\frac{\\pi}{2}$ | $\\cos\\theta \\approx 0$    |\n",
    "|     in oppposite directions if | $\\theta\\approx\\pi$           | $\\cos\\theta \\approx -1$   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb2a829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product =  17\n"
     ]
    }
   ],
   "source": [
    "def dot_product(x,y):\n",
    "  return sum(x*y)\n",
    "\n",
    "a = np.array([1,3])\n",
    "b = np.array([2,5])\n",
    "\n",
    "print(\"Dot Product = \", dot_product(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd33212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cos_d(a,b) =  0.9982743731749958\n",
      " cos_d(a,c) =  0.6643638388299197\n",
      " cos_d(a,d) =  0.14142135623730948\n",
      " cos_d(a,e) =  -0.8944271909999159\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,3])\n",
    "b = np.array([2,5])\n",
    "c = np.array([7,3])\n",
    "d = np.array([-4,2])\n",
    "e = np.array([-5,-5])\n",
    "\n",
    "print(\" cos_d(a,b) = \", dot_product(a,b) / (norm(a,2) * norm(b,2)))\n",
    "print(\" cos_d(a,c) = \", dot_product(a,c) / (norm(a,2) * norm(c,2)))\n",
    "print(\" cos_d(a,d) = \", dot_product(a,d) / (norm(a,2) * norm(d,2)))\n",
    "print(\" cos_d(a,e) = \", dot_product(a,e) / (norm(a,2) * norm(e,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

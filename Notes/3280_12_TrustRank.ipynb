{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b167603d-583e-48f6-a9c9-64cc1598d787",
   "metadata": {},
   "source": [
    "# Lecture 12 TrustRank\n",
    "__Math 3280: Data Mining__\n",
    "\n",
    "__Outline__\n",
    "1. TrustRank\n",
    "2. Spam Farms\n",
    "3. SpamMass\n",
    "\n",
    "__Reading__ \n",
    "* Leskovec, Chapter 5\n",
    "* [PageRank: Link Analysis Explanation and Python Implementation from Scratch, *Towards Data Science*](https://towardsdatascience.com/pagerank-3c568a7d2332)  \n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4c7ff-ff6f-40c0-824b-9b55c78bf80b",
   "metadata": {},
   "source": [
    "### 5.4 Link Spam\n",
    "We talked earlier about term spam, where spammers add specific words to their webpage to increase the search results. We effectively combated that by looking at links to each page using PageRank. However, there are groups that have found a way around PageRank. This is called __link spam__ which increases the PageRank of a spam page by use of a series of sites called a __spam farm__.\n",
    "\n",
    "Spammers are dealing with three different types of pages:\n",
    "1. Inaccessible pages\n",
    "    * Spammers can do nothing about these pages\n",
    "    * Generally don't link to spam pages\n",
    "2. Accessible pages\n",
    "    * Spammers can't change the page, but can manipulate them\n",
    "    * For example, on a blog, the spammer can't change what's on the page, but they can add a comment to the effect of \"Good points! I have some additional comments at [link to spam page].\"\n",
    "3. Own pages\n",
    "    * A series of pages that the spammer owns and controls, adding links to their target page(s)\n",
    "  \n",
    "To analyze a spam farm, let's define the following:\n",
    "* $t$: The spammer's target page\n",
    "* $x$: The PageRank of $t$ from Accessible Pages\n",
    "* $m$: The number of pages in the spam farm\n",
    "* $y$: Total (unknown) PageRank for the target page $t$\n",
    "\n",
    "We can calculate the PageRank for $t$ from a single page in the Spam Farm as the probability of being directed to $t$ from any page $z_i$ within the spam farm as ($\\beta y/m$) plus the probability of being teleported to that page ($(1-\\beta)/n$).\n",
    "$$z_i = \\frac{\\beta y}{m} + \\frac{1-\\beta}{n}$$\n",
    "\n",
    "The contribution from the entire spam farm is then $z=mz_i$\n",
    "\n",
    "We can now calculate the total PageRank for $t$:\n",
    "1. There is no contribution from Inaccessible Pages\n",
    "2. The contribution from Accessible Pages is simply $x$\n",
    "3. The contribution from the Spam Farm is $\\beta z + (1-\\beta)/n$\n",
    "    * The last term $(1-\\beta)/n$ is so small that it is relatively insignificant\n",
    "$$y = x + \\beta z + \\cancel{\\frac{1-\\beta}{n}}= x + \\beta m\\left(\\frac{\\beta y}{m} + \\frac{1-\\beta}{n}\\right) + \\cancel{\\frac{1-\\beta}{n}}$$\n",
    "$$y = x + \\beta^2 y + \\beta(1-\\beta)\\frac{m}{n}$$\n",
    "\n",
    "Solving for $y$,\n",
    "$$y - \\beta^2 y = x + \\beta(1-\\beta)\\frac{m}{n}$$\n",
    "$$y = \\frac{x}{1-\\beta^2} + \\frac{\\beta(1-\\beta)}{1-\\beta^2}\\frac{m}{n}$$\n",
    "$$y = \\frac{x}{1-\\beta^2} + \\frac{\\beta(1-\\beta)}{(1-\\beta)(1+\\beta)}\\frac{m}{n}$$\n",
    "$$y = \\frac{x}{1-\\beta^2} + \\frac{\\beta}{1+\\beta}\\frac{m}{n}$$\n",
    "\n",
    "Thus we see that the PageRank contribution from Accessible Pages is $x/(1-\\beta^2)$ and the contribution from the spam farm is proportional to the ratio of the farm's size to the entire internet $(m/n)$.\n",
    "\n",
    "__Example__: If we are calculating the PageRank of a $link spam$ page using a taxation parameter of $\\beta = 0.85$, then the contribution from accessible pages $x$ increases by a factor of,\n",
    "$$\\frac{1}{1-\\beta^2} = 3.60 = 360\\%$$\n",
    "\n",
    "while the contribution from the spam farm itself is the ratio $m/n$, increased by the factor,\n",
    "$$\\frac{\\beta}{1+\\beta} = 0.46 = 46\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90941dca-5f02-4249-8b45-cd0bfc581bcf",
   "metadata": {},
   "source": [
    "### Combating Link Spam\n",
    "We have found that using PageRank discourages the use of term spam. How can we combat link spam? We do this simply with two tools:\n",
    "1. TrustRank\n",
    "2. Spam Mass\n",
    "\n",
    "__TrustRank__ is simply a topic-sensitive PageRank, but the set of pages is set to a set of *trusted* pages.\n",
    "* The likelihood of a trusted page linking to a spam page is very small\n",
    "* Two common approaches for determining trusted pages:\n",
    "   1. Humans examine pages and determine if they are trustworthy or not\n",
    "       * Requires a lot of hands-on work, which means pages are sent in small batches to people\n",
    "   2. Picking a domain whose membership is controlled (.edu, .mil, .gov, .ac.il, .edu.sg)\n",
    " \n",
    "Two major issues with TrustRank are (1) building the trusted set by human inspection requires a lot of work, so can only be done in small batches, and (2) all good pages need to somehow be reachable from the trusted set, which isn't always the case. The bottom line is that TrustRank is very effective at filtering out link spam, but also filters out valid but less common webpages in the meantime.\n",
    "\n",
    "The idea of __Spam Mass__ is to calculate the \"percentage\" of the PageRank that is from spam. If we assume the PageRank is a combination of TrustRank ($t$) and spam, then the PageRank ($r$) is the sum of the two. Thus, the contribution from spam is $r-t$. The percentage of the PageRank from spam is then,\n",
    "$$Spam~Mass = \\frac{r-t}{r} = 1 - \\frac{t}{r}$$\n",
    "\n",
    "Now, a percentage will be a number between 0 and 1. However, the TrustRank can be larger than the PageRank, which will give a negative number. So,\n",
    "* If the Spam Mass is negative, it is a trusted site\n",
    "* If the Spam Mass is close to 0, it has a low chance of being a trusted site\n",
    "* If the Spam Mass is close to 1, it has a very low TrustRank score, so is likely spam\n",
    "\n",
    "The following three cells use Figure 5.1 to calculate the PageRank, the TrustRank (using $B$ and $D$ as trusted pages), and the Spam Mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f630fcf1-6e21-490d-a937-41ae28c2c2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank = [0.33333333 0.22222222 0.22222222 0.22222222]\n"
     ]
    }
   ],
   "source": [
    "### PageRank ###\n",
    "# Transition Matrix\n",
    "import numpy as np\n",
    "#              Starting Page     A,   B,   C,   D\n",
    "transition_matrix = np.array([[  0, 1/2,   1,   0],  # Linked page A\n",
    "                              [1/3,   0,   0, 1/2],  #             B\n",
    "                              [1/3,   0,   0, 1/2],  #             C\n",
    "                              [1/3, 1/2,   0,   0]]) #             D\n",
    "\n",
    "# Starting vector\n",
    "pagerank = np.array([1/4, 1/4, 1/4, 1/4])\n",
    "\n",
    "# Web surfer steps\n",
    "for i in range(30):\n",
    "    pagerank = np.matmul(transition_matrix, pagerank)\n",
    "\n",
    "print(f\"PageRank = {pagerank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e44c72b-9f80-4e9c-9e9f-ffb9783b8471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrustRank = [0.25714286 0.28095238 0.18095238 0.28095238]\n"
     ]
    }
   ],
   "source": [
    "### TrustRank ###\n",
    "# Starting vector\n",
    "trustrank = np.array([0, 1/2, 0, 1/2])\n",
    "\n",
    "# Teleporting vector\n",
    "es = np.array([0, 1, 0, 1])\n",
    "beta = 0.80\n",
    "\n",
    "# Web surfer steps\n",
    "for i in range(20):\n",
    "    trustrank = beta*np.matmul(transition_matrix, trustrank) + es*(1-beta)/sum(es)\n",
    "\n",
    "print(f\"TrustRank = {trustrank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4f70759-7a00-4dd0-bfd1-29ede77964c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Mass = [-30.48211026 -56.124792   -31.399158   -56.124792     0.73347195]\n"
     ]
    }
   ],
   "source": [
    "### Spam Mass ###\n",
    "print(f\"Spam Mass = {1 - (trustrank/pagerank)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b64d2-219e-4075-9bdf-1d884ec1d9b1",
   "metadata": {},
   "source": [
    "* Since $B$ and $D$ were trusted pages, their scores are negative\n",
    "* $A$ and $C$ are linked to $B$ and $D$, so their Spam Masses are small\n",
    "* If a website $E$ were to be introduced that is not connected to $B$ and $D$, it would likely have a spam mass closer to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d762df27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Mass = [-30.48211026 -56.124792   -31.399158   -56.124792     0.73347195]\n"
     ]
    }
   ],
   "source": [
    "# Transition Matrix\n",
    "#              Starting Page     A,   B,   C,   D,   E\n",
    "transition_matrix = np.array([[  0, 1/2, 1/2,   0,   0],  # Linked page A\n",
    "                              [1/3,   0,   0, 1/2,   0],  #             B\n",
    "                              [1/3,   0,   0, 1/2,   0],  #             C\n",
    "                              [1/3, 1/2,   0,   0,   0],  #             D\n",
    "                              [  0,   0, 1/2,   0,   1]]) #             E <-- SPAM\n",
    "\n",
    "# Starting vector\n",
    "pagerank = np.array([1/5, 1/5, 1/5, 1/5, 1/5])\n",
    "trustrank = np.array([1/5, 1/5, 1/5, 1/5, 1/5])\n",
    "es = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "# Web surfer steps\n",
    "for i in range(30):\n",
    "    pagerank = np.matmul(transition_matrix, pagerank)\n",
    "    trustrank = beta*np.matmul(transition_matrix, trustrank) + es*(1-beta)/sum(es)\n",
    "\n",
    "print(f\"Spam Mass = {1 - (trustrank/pagerank)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1764eb-5859-4bd7-a595-75c199f0231c",
   "metadata": {},
   "source": [
    "-----\n",
    "## Homework\n",
    "* Exercise 5.1.1\n",
    "* Exercise 5.1.2\n",
    "* Exercise 5.1.7\n",
    "* Exercise 5.2.1\n",
    "* Exercise 5.3.1 - Use $\\beta=0.82$\n",
    "* Exercise 5.4.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9467044-2d87-4593-ae76-2bd7d1f68ee6",
   "metadata": {},
   "source": [
    "# 05 Frequent Itemsets\n",
    "__Math 3280 - Data Mining__ : Snow College : Dr. Michael E. Olson\n",
    "\n",
    "* Leskovec, Chapter 6\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a338a9c-138f-44e8-966f-28579453a9a5",
   "metadata": {},
   "source": [
    "We learned earlier in the semester about how similar two objects may be to each other. We'll turn now to association between two kinds of objects. That is, there may not be any similarity between two objects, but there may be a relationship between them. For example, milk and bread are not very similar at all, but they are frequently bought together.\n",
    "\n",
    "A __market-basket__ model describes relationships between two kinds of objects. \n",
    "* *items*\n",
    "* *baskets* (sometimes called *transactions*) consist of an *itemset*\n",
    "    * We usually assume that the size of the itemset is much smaller than the total number of items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c45140-9bb8-44c3-b043-a71213474be8",
   "metadata": {},
   "source": [
    "## Frequent\n",
    "An itemset is said to be \"frequent\" if a subset of items appears in many baskets. Thinking of this mathematically, take an itemset $I$. \n",
    "* Define the __support__ of $I$ to be the number of baskets for which $I$ is a subset\n",
    "* $I$ is frequent if $Support(I) > s$ where $s$ is the __support threshold__\n",
    "\n",
    "Consider the following sets of letters:\n",
    "* {A, B, C}\n",
    "* {B, C, F}\n",
    "* {B, C, D}\n",
    "* {C, D, E}\n",
    "* {B, C, E}\n",
    "* {A, C, D}\n",
    "* {B, E, F}\n",
    "* {B, C, E}\n",
    "\n",
    "For this example, let's set our support threshold to $s = 5$.\n",
    "\n",
    "A __singleton set__ is a set of just one item. The supports for all the singleton sets are:\n",
    "$$Support(A) = 2 \\qquad Support(B) = 6 \\qquad Support(C) = 7 \\qquad Support(D) = 3 \\qquad Support(E) = 4 \\qquad Support(F) = 2$$\n",
    "\n",
    "From this, only items $B$ and $C$ are frequent, since they are greater than $s$.\n",
    "\n",
    "Take the support for the __doubleton__ subset $I_1 = \\{B, E\\}$. If we have a support threshold of $s=4$, then $I_1$ is not frequent.\n",
    "\n",
    "$$Support(I_1) = \\text{\\# of times }\\{B,E\\}\\text{ appears} = 3 < s$$\n",
    "\n",
    "The subset $I_2 = \\{B, C\\}$ would be considered a frequent itemset, however.\n",
    "\n",
    "$$Support(I_2) = \\text{\\# of times }\\{B,C\\}\\text{ appears} = 5 > 4$$\n",
    "\n",
    "How can we use this information? Sometimes, the results of this calculation are useless. For example, the purchase of milk and eggs would be considered similar since they are often purchased together. However, hot dogs and mustard are not considered similar, but they would have a higher support. This opens a market tactic: offer a sale on hot dogs, but increase the price of mustard. When people buy hot dogs because they are on sale, they may say, \"Oh, I need mustard,\" and they'll get it regardless of the price.\n",
    "\n",
    "Common applications of frequent itemsets:\n",
    "1. *Related concepts*: words that often appear in conjunction with a topic. For example, how often does the word \"civil\" come up in an article about \"engineering\"\n",
    "2. *Plagiarism*: sentences that appear in different documents. A document that has a large number of sentences with high support may be indicative of a plagiarized document\n",
    "3. *Biomarkers*: genes or proteins appear when exposed to certain deseases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac353d-b876-467f-9c3e-ba7fe8e94323",
   "metadata": {},
   "source": [
    "## Association Rules\n",
    "Now, we want to look at how often different subsets appear together. A common application of this would be recommendation systems (\"customers who bought what is in your cart also bought [item]\"). To indicate the association of basket $I$ with item $j$ as $I\\to j$.\n",
    "\n",
    "So, how likely will basket $I$ be associated with $j$? We'll measure this be defining the __confidence__ of $I\\to j$ as,\n",
    "$$Confidence(I\\to j) = \\frac{Support(I\\cup \\{j\\})}{Support(I)}$$\n",
    "\n",
    "Using our earlier example, how likely is the set $I = \\{B, C\\}$ to be associated with $\\{E\\}$?\n",
    "$$Confidence(\\{B,C\\} \\to \\{E\\}) = \\frac{Support(\\{B, C, E\\})}{Support(\\{B, C\\})} = \\frac{2}{5}$$\n",
    "\n",
    "Another way to think of this: The set $\\{B,C\\}$ appears 5 times. Of those 5 times, $E$ appears twice.\n",
    "\n",
    "The confidence is useful as long as $Support(I)$ is fairly large. However, the confidence means more when the association rule reflects a true relationship. So, we define the __interest__ of an association rule as the difference between the confidence and the fraction of baskets that contain $j$.\n",
    "$$Interest(I\\to j) = Confidence(I\\to j) - \\frac{Support(\\{j\\})}{\\text{\\# of baskets}}$$\n",
    "\n",
    "The advantage to this is that if $I$ and $j$ aren't associated, then $Confidence(I\\to j) \\approx \\frac{Support(\\{j\\})}{\\text{\\# of baskets}}$, so $Interest(\\{B,C\\}\\to\\{E\\}) \\approx 0$\n",
    "\n",
    "Using our earlier example,\n",
    "$$Interest(\\{B,C\\}\\to\\{E\\}) = Confidence(\\{B,C\\} \\to \\{E\\}) - \\frac{Support(E)}{8}$$\n",
    "$$Interest(\\{B,C\\}\\to\\{E\\}) = \\frac{Support(\\{B, C, E\\})}{Support(\\{B, C\\})} - \\frac{Support(E)}{8} = \\frac{2}{5} - \\frac{4}{8} = -\\frac{1}{10}$$\n",
    "\n",
    "What do the numbers mean?\n",
    "* If the interest is high, then $I$ has a high probability of causing $j$\n",
    "* If the interest is highly negative, then $I$ has a high probability of discouraging $j$\n",
    "* If the interest is near 0, then any association between $I$ and $j$ is likely coincidental\n",
    "\n",
    "How does this compare with others? Find the Confidence and Interest of $\\{A,B\\}\\to\\{C\\}$, $\\{B,F\\}\\to\\{E\\}$, $\\{C,D\\}\\to\\{A\\}$, and $\\{B,C\\}\\to\\{F\\}$.\n",
    "$$Confidence(\\{A,B\\}\\to\\{C\\}) = \\frac{1}{1} \\qquad Interest(\\{A,B\\}\\to\\{C\\}) = 1 - \\frac{7}{8} = \\frac{1}{8} = 0.125$$\n",
    "$$Confidence(\\{B,F\\}\\to\\{E\\}) = \\frac{1}{2} \\qquad Interest(\\{B,F\\}\\to\\{E\\}) = \\frac{1}{2} - \\frac{4}{8} = 0\\qquad\\qquad$$\n",
    "$$Confidence(\\{C,D\\}\\to\\{A\\}) = \\frac{1}{3} \\qquad Interest(\\{C,D\\}\\to\\{A\\}) = \\frac{1}{3} - \\frac{2}{8} = \\frac{1}{12} = 0.0833$$\n",
    "$$Confidence(\\{B,C\\}\\to\\{F\\}) = \\frac{1}{5} \\qquad Interest(\\{B,C\\}\\to\\{F\\}) = \\frac{1}{4} - \\frac{2}{8} = 0\\qquad\\qquad$$\n",
    "$$Confidence(\\{A,D\\}\\to\\{E\\}) = 0 \\qquad Interest(\\{A,D\\}\\to\\{E\\}) = 0 - \\frac{4}{8} = -\\frac{1}{2}\\qquad\\qquad$$\n",
    "\n",
    "With large datasets, a \"reasonably high\" interest would be items in 1\\% of the baskets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075cb8a8",
   "metadata": {},
   "source": [
    "## Calculations and Memory\n",
    "For a small company, the calculation could easily be done on one computer. For a large company, the number of transactions (baskets) is so large that the file holding it can't fit into the memory of one computer, so it needs to be done with some sort of Distributed File System and use an algorithm such as MapReduce to find frequent itemsets. But this can be really hard. It is addressed in more detail at the end of the chapter.\n",
    "\n",
    "Another possible problem that could take a lot of memory is the size of the baskets. Fortunately, most baskets are not that large. If we assume an average basket size of 20 items, then there are $\\begin{pmatrix} 20 \\\\ 2 \\end{pmatrix} = 190$ pairs of items. This can easily be done on a single computer.\n",
    "\n",
    "But that assumes we are doing pairs - only looking at 2 items at a time. If we want to look at larger subsets, the time for calculation increases. The time it takes is $n^k/k!$.\n",
    "* Usually we only need to deal with a subset of $k=2$ or $3$, so this usually doesn't become an issue\n",
    "* In the rare cases where $k$ is large, there are often items in the basket that can be ignored and dropped, decreasing $n$.\n",
    "\n",
    "Two methods to simplify this process are commonly used:\n",
    "1. Triangular Matrix method\n",
    "2. Triples method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae3ea9",
   "metadata": {},
   "source": [
    "### Triangular Matrix method\n",
    "Instead of creating a matrix, we can just use an array, where the index $k$ is found by,\n",
    "$$k=(i-1)\\left(n-\\frac{i}{2}\\right) + j - i$$\n",
    "\n",
    "where $1 \\le i < j \\le n$.\n",
    "* Note that we do not count when anything is paired with itself. $i$ is strictly less than $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a73ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1, j = 2, k = 1.0\n",
      "i = 1, j = 3, k = 2.0\n",
      "i = 1, j = 4, k = 3.0\n",
      "i = 1, j = 5, k = 4.0\n",
      "\n",
      "i = 2, j = 3, k = 5.0\n",
      "i = 2, j = 4, k = 6.0\n",
      "i = 2, j = 5, k = 7.0\n",
      "\n",
      "i = 3, j = 4, k = 8.0\n",
      "i = 3, j = 5, k = 9.0\n",
      "\n",
      "i = 4, j = 5, k = 10.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "for i in range(1,n+1):\n",
    "    for j in range(i+1,n+1):\n",
    "        k = (i-1)*(n-(i/2))+j-i\n",
    "        print(f\"i = {i}, j = {j}, k = {k}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6ecce",
   "metadata": {},
   "source": [
    "Since we are only considering cases where $i < j$, this changes from a full (sparse) $n\\times n$ matrix to the upper triangle above the diagonal (an $(n-1)\\times(n-1)$ triangle). If we are dealing with 4-byte integers, then this drops us from a matrix taking up $4n^2$ bytes down to $4\\cdot\\frac{1}{2}(n-1)^2 = 2(n-1)^2$ bytes.\n",
    "\n",
    "This is an improvement, but can still be sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6b993",
   "metadata": {},
   "source": [
    "### Triples method\n",
    "The advantage of the triples method is that we are only going to store information for each pair that *actually* occurs.\n",
    "\n",
    "The triples method involves taking a triple $[i,j,c]$ where $c$ is the count for the pair $\\{i,j\\}$.\n",
    "* Use a hash function with $i$ and $j$ to find where to store the data\n",
    "* Store the values of $i$, $j$, and $c$ at that location\n",
    "\n",
    "The advantage is that we are only storing data for each pair.\n",
    "\n",
    "The disadvantage is that for each pair, we have to store 3 values. If we are working with 4-byte integers, then that is 12 bytes per pair.\n",
    "* If more than 1/3 of possible pairs occur, the *triangular-matrix method* is better\n",
    "* If less than 1/3 of possible pairs occur, the *triples method* is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae9d81-a6f0-4f31-8bc1-08a35f367ad6",
   "metadata": {},
   "source": [
    "## A-Priori Algorithm\n",
    "This method is not too difficult. However, as is always the problem in the real world, we are dealing with very large amounts of data that can't always be held in main memory, much less do calculations with them. So, to simplify the process, we'll look at the __A-Priori__ algorithm, which only looks at the most frequent items.\n",
    "\n",
    "In order to understand the A-Priori algorithm, there are a few mathematical methods that need to be implemented. We won't go over these in detail here, but just give a quick summary. They are in section 6.2.3 - 6.2.4 of the *Leskovec* textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de49db2",
   "metadata": {},
   "source": [
    "### Monotonicity\n",
    "If a set $I$ of items is frequent, then so is every subset of $I$.\n",
    "\n",
    "A couple of points:\n",
    "* A subset $J\\subseteq I$ has the same frequency if $J=I$\n",
    "* J could be more frequent as $J$ could be a part of multiple subsets of $I$\n",
    "\n",
    "Example:\n",
    "* $I = \\{milk,bread,eggs,chips,salsa\\}$\n",
    "* $J = \\{milk,bread\\}$\n",
    "* If there are 20 people who bought $I$, then by default, the same 20 people also bought $J$\n",
    "* Additionally, there are some people who did not get $I$, but still got $J$:\n",
    "    * $\\{milk, bread, eggs\\}$\n",
    "    * $\\{milk, bread, chips\\}$\n",
    "    * $\\{milk, bread, chips, salsa\\}$\n",
    "    * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7b6c9-0518-44d4-b813-cc985e0bcb22",
   "metadata": {},
   "source": [
    "### The Algorithm\n",
    "The basic principle of the A-Priori is to decrease the number of calculations. But in order to do this, we make 2 passes through the data instead of just 1.\n",
    "\n",
    "__Pass 1__: Go through the data and count the frequency of each item\n",
    "* Select only the items with a support over the support threshold (again, often around 1\\%)\n",
    "* Begin with a list of $n$ items, narrow that down to $m$ items, where $m$ is a small fraction of $n$.\n",
    "\n",
    "__Pass 2__: For each basket, find only frequent items and count the pairs. Count all pairs for all baskets.\n",
    "\n",
    "If 50\\% of the items are eliminated, then since we are dealing with pairs, there will only be 25\\% of the calculations. This saves a lot on time and memory.\n",
    "\n",
    "In addition to being simple, this method can use monotonicity to find larger frequent $k$-sets.\n",
    "* Let $C_k$ be the set of candidate $k$-sets from the 1st pass\n",
    "* Find $L_k$, the set of truly frequent itemsets of size $k$\n",
    "* Use $L_k$ to find candidates for the $(k+1)$-set ($C_{k+1}$)\n",
    "\n",
    "From monotonicity, we know that there can only be the same (or fewer) number of frequent $(k+1)$-sets as there are frequent $k$-sets.\n",
    "* Each set $L_k$ gets smaller as $k$ increases\n",
    "* When $L_k$ is empty, then the largest frequent set is $L_{k-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f348a1-a530-4278-b86b-07dabac479f2",
   "metadata": {},
   "source": [
    "--------\n",
    "## Homework\n",
    "* Exercise 6.1.1 a,b,c\n",
    "* Exercise 6.1.2\n",
    "* Exercise 6.1.5 a,b - Find both the confidence and the interest of each association rule\n",
    "* Exercise 6.1.7 a\n",
    "* Exercise 6.2.6 a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd37974-a50c-459f-a6a9-d1d6a6c524d6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

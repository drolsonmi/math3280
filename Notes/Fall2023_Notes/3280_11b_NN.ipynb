{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the ANN\n",
    "The main method for finding the best weights is called __backpropagation__. The idea is that you start with the result $y$ and update the weights backwards progressively until you reach the input. The key is to find a way to measure the error, and then find how much the error changes as the weights change\n",
    "$$\\frac{\\partial E}{\\partial a}$$\n",
    "\n",
    "Let's start with a very simple example: A two-layer neural network (one input layer + one hidden layer), each with a width of 1. So, we have 3 nodes: an input node, a hidden node, and an output node:\n",
    "$$[x] \\qquad\\to\\qquad [z] \\qquad\\to\\qquad [y]$$\n",
    "$$z = f(x,a) \\qquad y = g(z,b)$$\n",
    "\n",
    "where $f$ and $g$ are the appropriate activation functions. Put in an input $x$ will give a result $y$. Let's define an error function to measure how accurate our results are:\n",
    "$$E = \\frac{1}{2}(y_0-y)^2$$\n",
    "\n",
    "Now, we want to find what values of $a$ and $b$ that will minimize $E$. To do this, we will use Gradient Descent\n",
    "\n",
    "> __Gradient Descent__ is a method to computationally find a minimum value. In summary:\n",
    "> 1. Find the slope of the function at a certain point\n",
    "> 2. Take a step in the direction of that slope to find a new x-value\n",
    "> 3. Repeat steps 1 and 2 until the x-value stops changing\n",
    ">\n",
    "> The size of step is known as the __learning rate__, which we will indicate as $\\delta$. In essence, it is the size of step for the x-variable, or like a $\\Delta x$.\n",
    "> * A large $\\delta$ will get you to the minimum in a hurry, as you have fewer steps, but it is not very accurate and could easily miss the minimum\n",
    "> * A small $\\delta$ is more accurate and could give better results, but there are two problems:\n",
    ">    * More likely to get stuck in a local minimum\n",
    ">    * Small steps means more steps, so it takes more time\n",
    "\n",
    "Using the chain rule, the derivative (slope) of the error function is,\n",
    "$$\\frac{\\partial E}{\\partial a} = -(y_0-y)\\frac{\\partial y}{\\partial a} = -(y_0-y)\\frac{\\partial y}{\\partial z}\\frac{\\partial z}{\\partial a}$$\n",
    "$$\\frac{\\partial E}{\\partial b} = -(y_0-y)\\frac{\\partial y}{\\partial b}$$\n",
    "\n",
    "This will tell us how quickly the error will change if the weights $a$ and $b$ change. Now that we know the slope, let's take a step.\n",
    "$$a_{1} = a_0 + \\delta \\frac{\\partial E}{\\partial a}$$\n",
    "$$b_{1} = b_0 + \\delta \\frac{\\partial E}{\\partial b}$$\n",
    "\n",
    "But the weights likely won't be perfect after one step, so we take multiple steps iteratively:\n",
    "$$a_{k+1} = a_k + \\delta \\frac{\\partial E}{\\partial a}$$\n",
    "$$b_{k+1} = b_k + \\delta \\frac{\\partial E}{\\partial b}$$\n",
    "\n",
    "We repeat this process multiple times until we get an unchanging $a$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of backpropagation\n",
    "Let's go back to our earlier example, but we'll define $f(x,a)=ax$ (a linear activation function) and $g(z,b)=ReLU(z,b) = \\left\\{\\begin{array}{ll}bz & z>0\\\\0 & z\\le 0\\end{array}\\right.$\n",
    "$$[x] \\qquad\\to\\qquad [z] \\qquad\\to\\qquad [y]$$\n",
    "$$z = f(x,a) \\qquad y = g(z,b)$$\n",
    "\n",
    "The partial derivatives of our error equation are:\n",
    "$$\\frac{\\partial E}{\\partial a} = -(y_0-y)\\frac{\\partial y}{\\partial z}\\frac{\\partial z}{\\partial a} = -(y_0-y)(b)(x)$$\n",
    "$$\\frac{\\partial E}{\\partial b} = -(y_0-y)\\frac{\\partial y}{\\partial b} = -(y_0-y)z = -(y_0-y)ax$$\n",
    "\n",
    "The iterations become:\n",
    "$$a_{k+1} = a_k + \\delta \\frac{\\partial E}{\\partial a} = a_k - \\delta(y_0-y)bx$$\n",
    "$$b_{k+1} = b_k + \\delta \\frac{\\partial E}{\\partial b} = b_k - \\delta(y_0-y)ax$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### m-layer Neural Network\n",
    "We need to expand our Neural Network so that it has a depth of $m$ and layers with a width more than 1.\n",
    "* Let $w^{(j)}_i$ be the $j$th weight of the $i$th layer\n",
    "* Let $\\vec{w}_i$ be the vector of all weights in the $i$th layer\n",
    "* Let $z_i = f_i(w^{(j)},x_j)$ be the activation function for the $i$th layer\n",
    "\n",
    "To find the change in error of a neural network with $m$ layers, we continue to use the chain rule through all the layers.\n",
    "$$\\frac{\\partial E}{\\partial w} = -(y_0-y)\\frac{\\partial y}{\\partial z_m}\\frac{\\partial z_m}{\\partial z_{m-1}}\\dots\\frac{\\partial z_2}{\\partial z_1}\\frac{\\partial z_1}{\\partial w}$$\n",
    "$$w'^{(j)}_i = w^{(j)}_i + \\delta\\frac{\\partial E}{\\partial w^{(j)}_i}$$\n",
    "\n",
    "If we want to consider all weights at once,\n",
    "$$\\vec{w}'_i = \\vec{w}_i + \\delta\\nabla E$$\n",
    "where\n",
    "$$\\nabla E = \\begin{bmatrix}\\vdots \\\\ \\frac{\\partial E}{\\partial w^{(j)}_i} \\\\ \\vdots\\end{bmatrix}$$\n",
    "\n",
    "Notes on multi-dimensional neural networks:\n",
    "* In 1- or 2-dimensions, it is relatively easy to find a minimum. Even if we get stuck in a localized minimum, we have techniques (like stochastic gradient descent) to help us. But in multiple dimensions, it is very rare to truly find a minimum.\n",
    "* Initial weights can often be determined using random number generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
